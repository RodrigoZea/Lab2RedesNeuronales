{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorio 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redes Neuronales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rodrigo Zea - 17058"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo del laboratorio es desarrollar una red neuronal con el propósito de entrenar dicha red con un dataset de entrenamiento repleto de imagenes de artículos de ropa (camisas, vestidos, pantalones, bolsones, etc) para luego poder decir qué artículo es el observado. Por ejemplo, si se está analizando la imagen de una camisa, que la red neuronal, efectivamente, diga que es una camisa y no es confundido por otro artículo.\n",
    "\n",
    "El dataset proveído es MNIST_Fashion, una alternativa al conocido MNIST, el cual es utilizado como benchmark para la mayoría de algoritmos de inteligencia artificial. MNIST_Fashion es una alternativa más compleja, debido a que muchos algoritmos sencillos pueden obtener un 97% de aciertos sin dificultad alguna en el MNIST original."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importación de librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mnist_reader\n",
    "from functools import reduce\n",
    "from scipy import optimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algunos métodos de utilidades externos al algoritmo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Método para inflar matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Para qué se usa? Se utiliza para \"inflar\" las matrices de las thetas luego de ser \"aplanadas\" en el algoritmo, entran al método como vectores \"planos\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inflate_matrixes(flat_thetas, shapes):\n",
    "    layers = len(shapes) + 1\n",
    "    sizes = [shape[0] * shape[1] for shape in shapes]\n",
    "    steps = np.zeros(layers, dtype=int)\n",
    "\n",
    "    for i in range(layers - 1):\n",
    "        steps[i + 1] = steps[i] + sizes[i]\n",
    "\n",
    "    return [\n",
    "        flat_thetas[steps[i]: steps[i + 1]].reshape(*shapes[i])\n",
    "        for i in range(layers - 1)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función para aplanar matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten_list_of_arrays = lambda list_of_arrays: reduce(\n",
    "    lambda acc, v: np.array([*acc.flatten(), *v.flatten()]),\n",
    "    list_of_arrays\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función sigmoide para transportar entradas por capa a salidas correspondientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basado en implementacion de https://towardsdatascience.com/fashion-product-image-classification-using-neural-networks-machine-learning-from-scratch-part-e9fda9e47661\n",
    "sigmoid = lambda x: 1.0/(1.0 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algoritmo de Redes Neuronales principal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feed Forward, calcula la derivada (salidas) de cada capa neuronal por prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feed_forward(thetas, X):\n",
    "    a = [X]\n",
    "\n",
    "    for i in range(len(thetas)):\n",
    "        a.append(\n",
    "            sigmoid(\n",
    "                np.matmul(\n",
    "                    np.hstack((\n",
    "                        np.ones(len(X)).reshape(len(X), 1),\n",
    "                        a[i]\n",
    "                    )), thetas[i].T\n",
    "                )\n",
    "            )            \n",
    "        )\n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función de costo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(flat_thetas, shapes, X, Y):\n",
    "    a = feed_forward(\n",
    "        inflate_matrixes(flat_thetas, shapes),\n",
    "        X\n",
    "    )\n",
    "    return -(Y * np.log(a[-1]) + (1 - Y) * np.log(1 - a[-1])).sum() / len(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back propagation, calcula las matrices de Delta[i, j], es el descenso a gradiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_prop(flat_thetas, shapes, X, Y):\n",
    "    m, layers = len(X), len(shapes) + 1\n",
    "    thetas = inflate_matrixes(flat_thetas, shapes)\n",
    "    \n",
    "    a = feed_forward(thetas, X)\n",
    "\n",
    "    # No existe necesidad de realizar un ciclo en estas operaciones aunque sean operaciones por capa\n",
    "    # Esto es debido a que son operaciones que se pueden simplificar con operaciones matriciales.\n",
    "    \n",
    "    # 2.3 en algoritmo\n",
    "    deltas = [*range(layers - 1), a[-1] - Y]\n",
    "    \n",
    "    # 2.4 en algoritmo\n",
    "    for i in range(layers - 2, 0, -1):\n",
    "        deltas[i] = np.matmul(deltas[i + 1], np.delete(thetas[i], 0, 1)) * (a[i] * (1 - a[i]))\n",
    "\n",
    "    # 2.5 y 3\n",
    "    Deltas = []\n",
    "    for i in range(layers - 1):\n",
    "        Deltas.append(\n",
    "            ( \n",
    "            np.matmul(\n",
    "                deltas[i + 1].T,\n",
    "                np.hstack((\n",
    "                    np.ones(len(a[i])).reshape(len(a[i]), 1),\n",
    "                    a[i]))\n",
    "                    )\n",
    "            ) / m\n",
    "        )\n",
    "    Deltas = np.asarray(Deltas)\n",
    "\n",
    "    return flatten_list_of_arrays(\n",
    "        Deltas\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lectura de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mnist_reader\n",
    "X_train, y_train = mnist_reader.load_mnist('data/fashion', kind='train')\n",
    "X_test, y_test = mnist_reader.load_mnist('data/fashion', kind='t10k')\n",
    "\n",
    "# reajuste\n",
    "X_train = X_train/1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preperación de datos para pasos posteriores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "m, n = X_train.shape\n",
    "y_train = y_train.reshape(m, 1)\n",
    "Y = (y_train == np.array(range(10))).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Red neuronal principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creación de red neuronal\n",
    "# La cantidad de elementos en el array son las capas, y la cantidad de cada elemento es la cantidad de neuronas\n",
    "NEURAL_NET = np.array([\n",
    "    n,\n",
    "    135,\n",
    "    10\n",
    "])\n",
    "\n",
    "# Obtención de shapes de theta (matriz con pesos de transición)\n",
    "theta_shapes = np.hstack((\n",
    "    NEURAL_NET[1:].reshape(len(NEURAL_NET) - 1, 1),\n",
    "    (NEURAL_NET[:-1] + 1).reshape(len(NEURAL_NET) - 1, 1)\n",
    "))\n",
    "\n",
    "# Se aplana theta \n",
    "flat_thetas = flatten_list_of_arrays([\n",
    "    np.random.rand(*theta_shape) * 0.01\n",
    "    for theta_shape in theta_shapes\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: RuntimeWarning: divide by zero encountered in log\n",
      "  \n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: RuntimeWarning: invalid value encountered in multiply\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Encontramos los mejores thetas para nuestra red neuronal utilizando optimize de la libreria scipy\n",
    "result = optimize.minimize(\n",
    "    fun = cost_function,\n",
    "    x0 = flat_thetas,\n",
    "    args=(theta_shapes, X_train, Y),\n",
    "    method='L-BFGS-B',\n",
    "    jac= back_prop,\n",
    "    options={'disp': True, 'maxiter': 3000}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Durante el procesamiento de datos, se desplegaron warnings debido a ciertas iteraciones que dieron como resultado NaN, sin embargo, el descenso a gradiente proveyó resultados válidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      fun: nan\n",
       " hess_inv: <107335x107335 LbfgsInvHessProduct with dtype=float64>\n",
       "      jac: array([-3.12796721e-06, -1.21035090e-14, -7.37880961e-14, ...,\n",
       "       -6.75105415e-09, -3.99548227e-08,  1.89774282e-10])\n",
       "  message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
       "     nfev: 9311\n",
       "      nit: 1433\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([-3.1836563 ,  0.00622807,  0.00536195, ...,  0.59574482,\n",
       "        1.66581616, -3.35844322])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107335"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thetaR = result.x\n",
    "thetaR.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('thetasOptimal.txt', thetaR, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "thetaR = np.loadtxt('thetasOptimal.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prueba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lectura de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test/1000\n",
    "m,_ = X_test.shape\n",
    "y_test = y_test.reshape(m,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Datos de resultados de theta (optimos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_thetas_top = thetasR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inflar thetas previamente aplanadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "superThetas = inflate_matrixes(flat_thetas_top,theta_shapes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Varios pasos en uno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feed forward de prediccion\n",
    "a = feed_forward(superThetas, X_test)\n",
    "\n",
    "# Indices de porcentaje máximo\n",
    "maximos = np.argmax(a[-1], axis = 1).reshape(m,1)\n",
    "correct = ((maximos == y_test)*1).sum()\n",
    "\n",
    "# Porcentajes de \"precision\" y errores\n",
    "accuracy = (correct/m)*100\n",
    "mistakes = 100.0 - accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resultados de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La precisión de acertados fue de: 87.03999999999999\n"
     ]
    }
   ],
   "source": [
    "print(\"La precisión de acertados fue de: \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El porcentaje de errores fue de: 12.960000000000008\n"
     ]
    }
   ],
   "source": [
    "print(\"El porcentaje de errores fue de: \" + str(mistakes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. El modelo tiene un porcentaje de acertados relativamente alto y mayor al teórico (se esperaba que fuera 80%).\n",
    "2. No tiene overfitting notable presente.\n",
    "3. Al analizar los casos, la mayoría de casos de errores fue debido a prendas altamente parecidas. Por ejemplo, vestidos y sacos, o zapatos en general."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
